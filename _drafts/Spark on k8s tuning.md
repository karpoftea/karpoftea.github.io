- выбор docker image
- выбор хранилища для shuffle
- оптимизация s3 fast upload
- настройка памяти
- (cost optimizations) запуск driver и executer на узлах разных конфигураций
- запуск spark-приложения в одной AZ (pod affinity)
- оптимизация сохранения данных в s3: S3A committers

Работа spark в k8s имеет особенности, которые нужно учитывать для того, чтобы развернутое spark-приложение эффективно использовало ресурсы.

## Локализация запуска приложения в одной зоне доступности
В целях отказоустойчивости в продуктовых инсталляциях используют мультизонный k8s-кластер в котором группа(ы) узлов тоже мультизонные. Это хорошо подходит для микросервисных приложений. Так например в случае если одна зона отказывает полностью, приложения уже развернутые в соседней зоне перенимают нагрузку, а те что были в отключенной постепенно мигрируют в работоспособную. Для spark-приложений развертывание приложения одновременно в двух зонах может обходиться дорого, поскольку облачные провадеры могут взымать плату за межзонный траффик, который будет создаваться за счет shuffle-операций. Поэтому имеет смысл настраивать зонную pod-affinity для driver-а и executer-ов. Пример такой настройки для spark-приложения запускаемого оператором выглядит так:
```yaml
this is pod-affinity example
```
В примере выше под драйвера запускается в любой зоне, а для подов executer-а настроена аффинитивность так, что они будут запущены в той же зоне, что и под драйвера. В итоге все приложение будет развернуто в одной зоне.

## Использование узлов различных конфигураций
Чтобы добиться значительной экономии на ресурсах используемых для spark-приложений можно использовать прерываемые-инстансы(preemptable, spot). Облачные провайдеры предлагают такие инстансы с большой скидкой (так в AWS spot-инстансы доступны со скидкой в 80%), причем инстанс может быть в любое время затребован обратно и отключен. Поскольку spark-приложения на уровне executer-а из коробки имеют механизм восстановления (в случае потери узла на котором работал executer-а данные будут пересчитаны при поднятии этого пода на другом узле), то использование прерываемых-инстансов это хороший способ сэкономить. Важно помнить, что под driver-а не должен находиться на прерываемом-инстансе поскольку потеря driver-а ведет к остановке приложения. (тут нужно разведать про HA в k8s)
Как правило в spark-приложении вся тяжелая работа выполняется на executer-ах, а driver является координатором. Поэтому для driver можно выбирать значительно менее производительную конфигурацию (не прерываемого) узла, а для executer-а - более производительную (но перываемого узла).